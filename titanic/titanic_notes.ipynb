{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on titanic binary classification project\n",
    "\n",
    "**Objective**: Here I attempt to build a simple neural network from scratch\n",
    "\n",
    "** Step 1 **: Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 2 **: Need to load data set from a csv file. Numpy's genfromtxt can be used, however, because ',' is present in string, use pandas's read_csv instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data sets\n",
    "train_set = pd.read_csv('data/train.csv', delimiter=',', quotechar='\"')\n",
    "test_set = pd.read_csv('data/test.csv', delimiter=',', quotechar='\"')\n",
    "\n",
    "#have a peep at the training data\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in Cabin = 687\n",
      "Missing data in each feature in training set:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Median age = 28.0\n",
      "Missing data in each feature in test set:\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "Median age in test set = 27.0\n"
     ]
    }
   ],
   "source": [
    "#data types in the training set\n",
    "#train_set.dtypes\n",
    "\n",
    "#missing data in 'Cabin'\n",
    "print('Missing data in ''Cabin'' =', train_set['Cabin'].isnull().sum())\n",
    "\n",
    "#total missing data\n",
    "print('Missing data in each feature in training set:\\n', train_set.isnull().sum())\n",
    "\n",
    "#replacing missing values in 'Age' with median age\n",
    "median_age = train_set['Age'].median()\n",
    "train_set['Age'].fillna(median_age, inplace=True)\n",
    "print('Median age =', median_age)\n",
    "#print(train_set.isnull().sum())\n",
    "\n",
    "#check missing values in test set\n",
    "print('Missing data in each feature in test set:\\n', test_set.isnull().sum())\n",
    "#also replace mssing values in 'Age' with median age\n",
    "median_age = test_set['Age'].median()\n",
    "test_set['Age'].fillna(median_age, inplace=True)\n",
    "print('Median age in test set =', median_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the training set is correctly (891, 12), and that of the test set (418, 11). Note that the test set has one fewer input feature because we don't know the survival of each passenger.\n",
    "\n",
    "Next, determine the number of training examples n_train to be 891 and  number of test examples n_test 418."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: n_train = 891\n",
      "Number of testing examples: n_test = 418\n",
      "Number of features for each example: n_x = 10\n"
     ]
    }
   ],
   "source": [
    "n_train = train_set.shape[0]\n",
    "n_test = test_set.shape[0]\n",
    "n_x = train_set.shape[1]-2 #passenger ID and survived\n",
    "\n",
    "print(\"Number of training examples: n_train = \" + str(n_train))\n",
    "print(\"Number of testing examples: n_test = \" + str(n_test))\n",
    "print(\"Number of features for each example: n_x = \" + str(n_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features to train =  6\n",
      "X_train [[3 1 22.0 1 0 7.25]\n",
      " [1 0 38.0 1 0 71.2833]\n",
      " [3 0 26.0 0 0 7.925]\n",
      " ...\n",
      " [3 0 28.0 1 2 23.45]\n",
      " [1 1 26.0 0 0 30.0]\n",
      " [3 1 32.0 0 0 7.75]]\n",
      "X_test [[3 1 34.5 0 0 7.8292]\n",
      " [3 0 47.0 1 0 7.0]\n",
      " [2 1 62.0 0 0 9.6875]\n",
      " [3 1 27.0 0 0 8.6625]\n",
      " [3 0 22.0 1 1 12.2875]]\n"
     ]
    }
   ],
   "source": [
    "#Extract data from train_set\n",
    "train_features = [train_set['Pclass'], train_set['Sex'], train_set['Age'], train_set['SibSp'], train_set['Parch'], train_set['Fare']]\n",
    "X1 = pd.concat(train_features, axis=1)\n",
    "#X1.head()\n",
    "n_features = X1.shape[1]\n",
    "print('Number of features to train = ', n_features)\n",
    "\n",
    "#Extract data into X_train and Y_train, now numpy arrays -- not a good way!!!!\n",
    "X_train = X1.iloc[:, :].values #matrix dimensions (n_train, n_x-4) excluded 'Name', 'Ticket', 'Cabin', 'Embarked'\n",
    "Y_train = train_set.iloc[:, 1].values #vector dimension (n_train)\n",
    "gender = preprocessing.LabelEncoder()\n",
    "X_train[:, 1] = gender.fit_transform(X_train[:, 1])\n",
    "print('X_train', X_train[:, :])\n",
    "\n",
    "#Extract data from train_set\n",
    "test_features = [test_set['Pclass'], test_set['Sex'], test_set['Age'], test_set['SibSp'], test_set['Parch'], test_set['Fare']]\n",
    "X2 = pd.concat(test_features, axis=1)\n",
    "X2.head()\n",
    "\n",
    "X_test = X2.iloc[:, :].values\n",
    "X_test[:, 1] = gender.fit_transform(X_test[:, 1])\n",
    "print('X_test', X_test[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [[ 0.82737724  0.73769513 -0.56573646  0.43279337 -0.47367361 -0.50244517]\n",
      " [-1.56610693 -1.35557354  0.66386103  0.43279337 -0.47367361  0.78684529]\n",
      " [ 0.82737724 -1.35557354 -0.25833709 -0.4745452  -0.47367361 -0.48885426]\n",
      " ...\n",
      " [ 0.82737724 -1.35557354 -0.1046374   0.43279337  2.00893337 -0.17626324]\n",
      " [-1.56610693  0.73769513 -0.25833709 -0.4745452  -0.47367361 -0.04438104]\n",
      " [ 0.82737724  0.73769513  0.20276197 -0.4745452  -0.47367361 -0.49237783]] (6, 891)\n",
      "X_test [[ 0.87348191  0.75592895  0.38623105 -0.49947002 -0.4002477  -0.49781052]\n",
      " [ 0.87348191 -1.32287566  1.37137004  0.61699237 -0.4002477  -0.51265996]\n",
      " [-0.31581919  0.75592895  2.55353683 -0.49947002 -0.4002477  -0.46453181]\n",
      " ...\n",
      " [ 0.87348191  0.75592895  0.70147553 -0.49947002 -0.4002477  -0.50818292]\n",
      " [ 0.87348191  0.75592895 -0.20485235 -0.49947002 -0.4002477  -0.4938564 ]\n",
      " [ 0.87348191  0.75592895 -0.20485235  0.61699237  0.61989583 -0.23762123]] (6, 418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#normalizing inputs - appears to me so far using mean and variance \n",
    "sc = preprocessing.StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_trainT = np.transpose(X_train)\n",
    "\n",
    "X_test = sc.fit_transform(X_test)\n",
    "X_testT = np.transpose(X_test)\n",
    "print('X_train', X_train[:, :], X_trainT.shape)\n",
    "print('X_test', X_test[:, :], X_testT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we can extract the training examples $X$ and output labels $Y$ from the training set and implement the different functions as shown below. However, there are different data types in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 0.6789 - acc: 0.6094\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.5587 - acc: 0.7273\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4761 - acc: 0.7969\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.4616 - acc: 0.7980\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.4575 - acc: 0.8013\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.4461 - acc: 0.8047\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4400 - acc: 0.8036\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4365 - acc: 0.8025\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.4310 - acc: 0.8081\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4292 - acc: 0.8070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10bcbcc18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt to use Keras to train a fully connected network\n",
    "model = k.models.Sequential()\n",
    "\n",
    "#add input layer and the first hidden layer\n",
    "model.add(k.layers.Dense(5, kernel_initializer='uniform', input_shape=(n_features,), activation='relu'))\n",
    "\n",
    "#add second hidden layer\n",
    "model.add(k.layers.Dense(5, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "#add output layer\n",
    "model.add(k.layers.Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "#compile network\n",
    "optimizer = k.optimizers.Adam(lr=0.005)\n",
    "model.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#run network\n",
    "model.fit(X_train, Y_train, batch_size=20, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 1)\n",
      "Number of passengers predicted to survive = Survived    149\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in greater\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test, batch_size=100)\n",
    "Y_pred = (Y_pred > 0.5).astype(int)\n",
    "print(Y_pred.shape)\n",
    "Y = pd.DataFrame({'Survived' : Y_pred[:, 0]})\n",
    "submission = pd.concat((test_set['PassengerId'], Y), axis=1)\n",
    "submission.head(100)\n",
    "print('Number of passengers predicted to survive =', Y.sum())\n",
    "submission.to_csv('data/submission_AR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
