{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on titanic binary classification project\n",
    "\n",
    "**Objective**: Here I attempt to build a simple neural network from scratch\n",
    "\n",
    "** Step 1 **: Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 2 **: Need to load data set from a csv file. Numpy's genfromtxt can be used, however, because ',' is present in string, use pandas's read_csv instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data sets\n",
    "train_set = pd.read_csv('data/train.csv', delimiter=',', quotechar='\"')\n",
    "test_set = pd.read_csv('data/test.csv', delimiter=',', quotechar='\"')\n",
    "\n",
    "#have a peep at the training data\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in Cabin = 687\n",
      "Missing data in each feature in training set:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Median age = 28.0\n",
      "Missing data in each feature in test set:\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "Median age in test set = 27.0\n"
     ]
    }
   ],
   "source": [
    "#data types in the training set\n",
    "#train_set.dtypes\n",
    "\n",
    "#missing data in 'Cabin'\n",
    "print('Missing data in ''Cabin'' =', train_set['Cabin'].isnull().sum())\n",
    "\n",
    "#total missing data\n",
    "print('Missing data in each feature in training set:\\n', train_set.isnull().sum())\n",
    "\n",
    "#replacing missing values in 'Age' with median age\n",
    "median_age = train_set['Age'].median()\n",
    "train_set['Age'].fillna(median_age, inplace=True)\n",
    "print('Median age =', median_age)\n",
    "#print(train_set.isnull().sum())\n",
    "\n",
    "#check missing values in test set\n",
    "print('Missing data in each feature in test set:\\n', test_set.isnull().sum())\n",
    "#also replace mssing values in 'Age' with median age\n",
    "median_age = test_set['Age'].median()\n",
    "test_set['Age'].fillna(median_age, inplace=True)\n",
    "print('Median age in test set =', median_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the training set is correctly (891, 12), and that of the test set (418, 11). Note that the test set has one fewer input feature because we don't know the survival of each passenger.\n",
    "\n",
    "Next, determine the number of training examples n_train to be 891 and  number of test examples n_test 418."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: n_train = 891\n",
      "Number of testing examples: n_test = 418\n",
      "Number of features for each example: n_x = 10\n"
     ]
    }
   ],
   "source": [
    "n_train = train_set.shape[0]\n",
    "n_test = test_set.shape[0]\n",
    "n_x = train_set.shape[1]-2 #passenger ID and survived\n",
    "\n",
    "print(\"Number of training examples: n_train = \" + str(n_train))\n",
    "print(\"Number of testing examples: n_test = \" + str(n_test))\n",
    "print(\"Number of features for each example: n_x = \" + str(n_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features to train =  6\n",
      "X_train [[3 1 22.0 1 0 7.25]\n",
      " [1 0 38.0 1 0 71.2833]\n",
      " [3 0 26.0 0 0 7.925]\n",
      " ...\n",
      " [3 0 28.0 1 2 23.45]\n",
      " [1 1 26.0 0 0 30.0]\n",
      " [3 1 32.0 0 0 7.75]]\n",
      "X_test [[3 1 34.5 0 0 7.8292]\n",
      " [3 0 47.0 1 0 7.0]\n",
      " [2 1 62.0 0 0 9.6875]\n",
      " [3 1 27.0 0 0 8.6625]\n",
      " [3 0 22.0 1 1 12.2875]]\n"
     ]
    }
   ],
   "source": [
    "#Extract data from train_set\n",
    "train_features = [train_set['Pclass'], train_set['Sex'], train_set['Age'], train_set['SibSp'], train_set['Parch'], train_set['Fare']]\n",
    "X1 = pd.concat(train_features, axis=1)\n",
    "#X1.head()\n",
    "n_features = X1.shape[1]\n",
    "print('Number of features to train = ', n_features)\n",
    "\n",
    "#Extract data into X_train and Y_train, now numpy arrays -- not a good way!!!!\n",
    "X_train = X1.iloc[:, :].values #matrix dimensions (n_train, n_x-4) excluded 'Name', 'Ticket', 'Cabin', 'Embarked'\n",
    "Y_train = train_set.iloc[:, 1].values #vector dimension (n_train)\n",
    "gender = preprocessing.LabelEncoder()\n",
    "X_train[:, 1] = gender.fit_transform(X_train[:, 1])\n",
    "print('X_train', X_train[:, :])\n",
    "\n",
    "#Extract data from train_set\n",
    "test_features = [test_set['Pclass'], test_set['Sex'], test_set['Age'], test_set['SibSp'], test_set['Parch'], test_set['Fare']]\n",
    "X2 = pd.concat(test_features, axis=1)\n",
    "X2.head()\n",
    "\n",
    "X_test = X2.iloc[:, :].values\n",
    "X_test[:, 1] = gender.fit_transform(X_test[:, 1])\n",
    "print('X_test', X_test[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [[ 0.82737724  0.73769513 -0.56573646  0.43279337 -0.47367361 -0.50244517]\n",
      " [-1.56610693 -1.35557354  0.66386103  0.43279337 -0.47367361  0.78684529]\n",
      " [ 0.82737724 -1.35557354 -0.25833709 -0.4745452  -0.47367361 -0.48885426]\n",
      " ...\n",
      " [ 0.82737724 -1.35557354 -0.1046374   0.43279337  2.00893337 -0.17626324]\n",
      " [-1.56610693  0.73769513 -0.25833709 -0.4745452  -0.47367361 -0.04438104]\n",
      " [ 0.82737724  0.73769513  0.20276197 -0.4745452  -0.47367361 -0.49237783]] (6, 891)\n",
      "X_test [[ 0.87348191  0.75592895  0.38623105 -0.49947002 -0.4002477  -0.49781052]\n",
      " [ 0.87348191 -1.32287566  1.37137004  0.61699237 -0.4002477  -0.51265996]\n",
      " [-0.31581919  0.75592895  2.55353683 -0.49947002 -0.4002477  -0.46453181]\n",
      " ...\n",
      " [ 0.87348191  0.75592895  0.70147553 -0.49947002 -0.4002477  -0.50818292]\n",
      " [ 0.87348191  0.75592895 -0.20485235 -0.49947002 -0.4002477  -0.4938564 ]\n",
      " [ 0.87348191  0.75592895 -0.20485235  0.61699237  0.61989583 -0.23762123]] (6, 418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#normalizing inputs - appears to me so far using mean and variance \n",
    "sc = preprocessing.StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_trainT = np.transpose(X_train)\n",
    "\n",
    "X_test = sc.fit_transform(X_test)\n",
    "X_testT = np.transpose(X_test)\n",
    "print('X_train', X_train[:, :], X_trainT.shape)\n",
    "print('X_test', X_test[:, :], X_testT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "\n",
    "This is a binary classification problem––a simple neural network using logistic regression may work. Let's review the theory.\n",
    "\n",
    "We have a training set inputs represented by a matrix $X = [x^{(1)}, x^{(2)},\\cdots, x^{(m)}]$, where $m$ is the number of training examples, `n_train`. The shape of $X$ is $(n_x, m)$, $n_x$ is the number of input features.\n",
    "\n",
    "The output label vector for the training set $Y = [y^{(1)}, y^{(2)}, \\cdots, y^{(m)}]$ has the dimension $(1, m)$, where $y^{(i)}=0$ or $1$. Our goal is basically to find a function that best describes the relationship between $X$ and $Y$, or best fitting function. \n",
    "\n",
    "$\\hat{y}$ is an estimate of how likely $y=1$ given $x$, $\\hat{y} = P(y=1 | x)$, and given the probability nature of the problem, the sigmoid function is used to map a predicted value into a probability, that is, a number between 0 and 1.\n",
    "\n",
    "$$\\hat{y} ^{(i)} = a^{(i)} = \\mathrm{sigmoid}(z^{(i)}) = \\sigma(z^{(i)}) = \\frac{1}{1 + e^{-z^{(i)}}}$$\n",
    "\n",
    "where $z^{(i)} = w^T x^{(i)} + b$ for a training example (or data point), $x^{(i)}$. Here $b$ is a bias vector, $a^{(i)}$ is called the activation function, the weight matrix $w$ can be understood as fitting coefficients, which give the \"importance\" or contribution of each input feature.\n",
    "\n",
    "It follows that the loss function: $\\mathcal{L}(a^{(i)}, y^{(i)}) = -y^{(i)}log(a^{(i)})-(1-y^{(i)})log(1-a^{(i)})$\n",
    "\n",
    "This is a logistic loss function.\n",
    "\n",
    "The cost function: \n",
    "$$J = \\frac{1}{m}\\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})$$\n",
    "\n",
    "The basic structure of a neural network:\n",
    "* Calculate the current loss (forward propagation)\n",
    "* Calculate the current gradient (backward propagation)\n",
    "* Update parameters (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we can extract the training examples $X$ and output labels $Y$ from the training set and implement the different functions as shown below. However, there are different data types in the training set, making this not a trivial task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "891/891 [==============================] - 4s 4ms/step - loss: 0.6753 - acc: 0.6072\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.5435 - acc: 0.7542\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4609 - acc: 0.7957\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.4473 - acc: 0.8025\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4398 - acc: 0.8013\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4339 - acc: 0.8103\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.4302 - acc: 0.8092\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4306 - acc: 0.8025\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4256 - acc: 0.8182\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.4230 - acc: 0.8137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3afe2b00>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt to use Keras to train a fully connected network\n",
    "model = k.models.Sequential()\n",
    "\n",
    "#add input layer and the first hidden layer\n",
    "model.add(k.layers.Dense(5, kernel_initializer='uniform', input_shape=(n_features,), activation='relu'))\n",
    "\n",
    "#add second hidden layer\n",
    "model.add(k.layers.Dense(5, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "#add output layer\n",
    "model.add(k.layers.Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "#compile network\n",
    "optimizer = k.optimizers.Adam(lr=0.005)\n",
    "model.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#run network\n",
    "model.fit(X_train, Y_train, batch_size=20, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 1)\n",
      "Number of passengers predicted to survive = Survived    144\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in greater\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test, batch_size=100)\n",
    "Y_pred = (Y_pred > 0.5).astype(int)\n",
    "print(Y_pred.shape)\n",
    "Y = pd.DataFrame({'Survived' : Y_pred[:, 0]})\n",
    "submission = pd.concat((test_set['PassengerId'], Y), axis=1)\n",
    "submission.head(100)\n",
    "print('Number of passengers predicted to survive =', Y.sum())\n",
    "submission.to_csv('data/submission_AR.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to implement:\n",
    "* `initialization` which initializes parameters\n",
    "* `forward propagation` which computes the activations $A = \\mathrm{sigmoid}(w^T X+b)$ where $A = (a^{(1)}, a^{(2)},\\cdots, a^{(m)})$, $m$ is the number of training examples, and the cost function $J$\n",
    "* `backward propagation` which computes the gradients\n",
    "$$\\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T$$\n",
    "$$\\frac{\\partial J}{\\partial b} = \\frac{1}{m}\\sum_{i=1}^m (a^{(i)}-y^{(i)})$$\n",
    "* `optimization` which minimizes the cost function $J$ using gradient descent. For any parameter $\\theta$, the update rule is $\\theta = \\theta-\\alpha d\\theta$ where $\\alpha$ is the learning rate.\n",
    "* `prediction` which makes the prediction using $\\hat{Y} = A = \\sigma(W^T X + b)$. Values smaller than a threshold (let's say 0.5) are converted into 0's and values larger than 0.5 are converted into 1's. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
